You should select [10] representative sentences! 

[]	For example, authors of movie reviews often devote large sections to (largely objective) descriptions of the plot (Pang and Lee, 2004). 
[1]	Kim and Hovy (2004) select candidate sentiment sentences and use word-based sentiment classifiers to classify unseen words into a negative or positive class. 
[]	Each document D therefore is represented as a bag-ofwords feature vector: D = braceleftbigw1,w2,,w|V |bracerightbig where |V| is the size of the vocabulary (i.e. the number of unique words) and wi, i = 1,,|V | is the weight of term i in document D. Despite the significant attention that sentiment analysis has received in recent years, the best accuracy without using complex features (Mullen and Collier, 2004; Whitelaw et al., 2005) or additional human annotations (Zaidan et al., 2007) is achieved by employing a binary weighting scheme (Pang et al., 2002), where wi = 1,if tfi > 0 and wi = 0,if tfi = 0, where tfi is the number of times that term i appears in document D (henceforth raw term frequency) and utilizing a SVM classifier.
[1]	Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005). 
[]	Specifically, we construct features using polarity lexicons (used by (Wilson et al., 2005)), DA tags (used by (Somasundaran 3Local is supervised, as previous work has shown that supervised methods are effective in opinion analysis. 
[]	Note that we select sentiment terms as those appear in the sentiment lexicon provided by MPQA project (Wilson et al., 2005). 
[]	Hatzivassiloglou and McKeown (1997) proposed a supervised algorithm to determine the semantic orientation of adjectives. 
[]	There has been a large and diverse body of research in opinion mining, with most research at the text (Pang et al., 2002; Pang and Lee, 2004; Popescu and Etzioni, 2005; Ounis et al., 2006), sentence (Kim and Hovy, 2005; Kudo and Matsumoto, 2004; Riloff et al., 2003; Yu and Hatzivassiloglou, 2003) or word (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Kim and Hovy, 2004; Takamura et al., 2005; Andreevskaia and Bergler, 2006; Kaji and Kitsuregawa, 2007) level.
[]	Each document D therefore is represented as a bag-ofwords feature vector: D = braceleftbigw1,w2,,w|V |bracerightbig where |V| is the size of the vocabulary (i.e. the number of unique words) and wi, i = 1,,|V | is the weight of term i in document D. Despite the significant attention that sentiment analysis has received in recent years, the best accuracy without using complex features (Mullen and Collier, 2004; Whitelaw et al., 2005) or additional human annotations (Zaidan et al., 2007) is achieved by employing a binary weighting scheme (Pang et al., 2002), where wi = 1,if tfi > 0 and wi = 0,if tfi = 0, where tfi is the number of times that term i appears in document D (henceforth raw term frequency) and utilizing a SVM classifier. 
[1]	More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). 
[]	Early research on document-level sentiment classification employed conventional machine learning techniques for text categorization (Pang et al., 2002). 
[1]	Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al. , 2005; Balog et al. , 2006), review classification (Turney, 2002; Pang et al. , 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al. , 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003).
[]	As seed words, we used subsets of the 1,336 adjectives that were manually classified as positive (657) or negative (679) by Hatzivassiloglou and McKeown (1997). 
[]	Starting with the Romanian lexicon, we developed a lexical classifier similar to the one introduced by (Riloff and Wiebe, 2003). 
[]	Recently, a variety of studies have been reported on sentiment classification at different levels: word level (Esuli and Sebastiani, 2005), phrase level (Wilson et al., 2009), sentence level (Kim and Hovy, 2004; Liu et al., 2005), and document level (Turney, 2002; Pang et al., 2002).
[1]	The span detector is based on conditional random fields (CRFs) (Lafferty, McCallum, and Pereira, 2001), which is a structured prediction learning framework common in sub-sentential natural language processing tasks, including sentiment analysis (Choi and Cardie, 2007; McDonald et al., 2007) The approach presented here resembles work by Morante and Daelemans (2009), who used IGTree to predict negation cues and a CRF metal earner that combined input from k-nearest neighbor classification, a support vector machine, and another underlying CRF to predict the scope of negations within the BioScope corpus. 
[]	While most of the works on sentiment analysis focus on full text, some works address sentiment analysis in the phrasal and sentence level, see (Yu and Hatzivassiloglou, 2003; Wilson et al., 2005; McDonald et al., 2007; Titov and McDonald, 2008a; Titov and McDonald, 2008b; Wilson et al., 2009; Tsur et al., 2010) among others.
[]	There have been attempts on tackling this so-called document-level subjectivity classification task, with very encouraging results (see Yu and Hatzivassiloglou (2003) and Wiebe et al. 
[]	Sentiment classification is a well studied problem (Wiebe, 2000; Pang et al., 2002; Turney, 2002) and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay (2007).
[1]	Sentiment analysis includes a variety of different problems, including: sentiment classification techniques to classify reviews as positive or negative, based on bag of words (Pang et al. , 2002) or positive and negative words (Turney, 2002; Mullen and Collier, 2004); classifying sentences in a document as either subjective or objective (Riloff and Wiebe, 2003; Pang and Lee, 2004); identifying or classifying appraisal targets (Nigam and Hurst, 2004); identifying the source of an opinion in a text (Choi et al. , 2005), whether the author is expressing the opinion, or whether he is attributing the opinion to someone else; and developing interactive and visual opinion mining methods (Gamon et al. , 2005; Popescu and Etzioni, 2005).
[]	Since adjectives have been a focus of previous work in sentiment detection (Hatzivassiloglou and Wiebe, 2000; Turney, 2002)13, we looked at the performance of using adjectives alone. 
[]	Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentiment bearing words. 
[1]	Cascaded models for fine-to-coarse sentiment analysis were studied by Pang and Lee (2004). 
[]	For these algorithms, already a low-level representation using bag of words is fairly effective (Pang et al., 2002). 
[]	SVM with unigrams & binary weights (Pang et al., 2002), reported at (Pang and Lee, 2004) 87.15% Hybrid SVM with Turney/Osgood Lemmas (Mullen and Collier, 2004) 86% SVM with min-cuts (Pang and Lee, 2004) 87.2% SVM with appraisal groups 90.2% (Whitelaw et al., 2005) SVM with log likehood ratio feature selection (Aue and Gamon, 2005) 90.45% SVM with annotator rationales 92.2% (Zaidan et al., 2007) LDA with filtered lexicon, subjectivity detection (Lin and He, 2009) 84.6% The approach is straightforward, intuitive, computationally efficient, doesnt require additional human effort and takes into consideration standardized and tested notions from IR. 
[1]	A common approach is to use a sentiment labelled lexicon to score sentences (Hatzivassiloglou and McKeown, 1997; Turney, 2002; Yu and Hatzivassiloglou, 2003). 
[1]	The second step is to estimate the semantic orientation of each extracted phrase (Hatzivassiloglou & McKeown, 1997). 
[1]	Automatic identification of subjective content often relies on word indicators, such as unigrams (Pang et al., 2002) or predetermined sentiment lexica (Wilson et al., 2005). 
[]	Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al. 
