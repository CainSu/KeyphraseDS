You should select [10] representative sentences! 

[]	They roughly fall into three categories according to what is used for supervision in learning process: (1) using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus, (Lesk, 1986; Lin, 1997; McCarthy et al. , 2004; Seo et al. , 2004; Yarowsky, 1992), (2) exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994; Diab and Resnik, 2002; Li and Li, 2004; Ng et al. , 2003), (3) bootstrapping sense tagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data (Hearst, 1991; Karov and Edelman, 1998; Mihalcea, 2004; Park et al. , 2000; Yarowsky, 1995).
[]	Two more recent investigations are by Yarowsky, (Yarowsky, 1995), and later, Mihalcea, (Mihalcea, 2002). 
[]	Results and evaluation We used two measurements, applicability and precision (Dagan and Itai 1994), to evaluate the performance of our method. 
[]	FY02 (Florian and Yarowsky, 2002), WSC04 (Wu et al. , 2004), LN02 (Lee and Ng, 2002) the unseen Senseval-3 test sets). 
[]	However, all possible feature values (collocated words) are used, without employing the feature value pruning method used in (Ng and Lee, 1996). 
[]	Both test sets are identical to the ones reported in (Ng and Lee, 1996). 
[1]	Prior research has shown that using Support Vector Machines (SVM) as the learning algorithm for WSD achieves good results (Lee and Ng, 2002). 
[]	The sense-tagged corpus SEMCOI~, prepared by (Miller et al. , 1994), contains a substantial subset of the Brown corpus tagged with the refined senses of WORDNET. 
[]	They roughly fall into three categories according to what is used for supervision in learning process: (1) using external resources, e.g., thesaurus or lexicons, to disambiguate word senses or automatically generate sense-tagged corpus, (Lesk, 1986; Lin, 1997; McCarthy et al. , 2004; Seo et al. , 2004; Yarowsky, 1992), (2) exploiting the differences between mapping of words to senses in different languages by the use of bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages) (Brown et al. , 1991; Dagan and Itai, 1994; Diab and Resnik, 2002; Li and Li, 2004; Ng et al. , 2003), (3) bootstrapping sense tagged seed examples to overcome the bottleneck of acquisition of large sense-tagged data (Hearst, 1991; Karov and Edelman, 1998; Mihalcea, 2004; Park et al. , 2000; Yarowsky, 1995). 
[1]	Many corpus based statistical methods have been proposed to solve this problem, including supervised learning algorithms (Leacock et al. , 1998; Towel and Voorheest, 1998), weakly supervised learning algorithms (Dagan and Itai, 1994; Li and Li, 2004; Mihalcea, 2004; Niu et al. , 2005; Park et al. , 2000; Yarowsky, 1995), unsupervised learning algorithms (or word sense discrimination) (Pedersen and Bruce, 1997; Schutze, 1998), and knowledge based algorithms (Lesk, 1986; McCarthy et al. , 2004).
[]	Total S1={tank, , , } 571664 S2={tank, } 8 23 5 36 Total 65 24 11 100 [Note] S1: a large container for storing liquid or gas S2: an enclosed heavily armed, armored vehicle (e) Polysemous word title (applicability=92.0%; precision=81.5%) Results Correct sense S1 S2S3 S4 ? Total S1={title, , , } 43100246 S2={title, , , , } 62601538 S3={title, , , } 11011 4 S4={title, } 3306012 Total 533108810 [Note] S1: a word or name given to a person to be used before his/her name as a sign rank, profession, etc. S2: a name given to a book, play, etc. S3: the legal right to own something S4: the position of being the winner of an sports competition (f) Polysemous word trial (applicability=92.0%; precision=92.4%) Results Correct sense S1 S2S3 S4 S5 ? Total S1={trial,,, } 623000570 S2={trial,, ,,, } 4230002 29 S3={trial, } 000001 1 S4={trial,, } 000000 0 S5={trial,,, } 000000 0 Total 626000810 [Note] S1: a legal process in which a court examines a case S2: a process of testing to determine quality, value, usefulness, etc. S3: a sports competition that tests a players ability S4: annoying thing or person S5: difficulties and troubles (Dagan and Itai 1994; Kikui 1998), where instances of co-occurrence in a first-language text are aligned with co-occurrences statistically extracted from the second language corpus. 
[]	Similarly to our work, (Resnik, 1995)(Agirre and Rigau, 1996) challenge the fine-grainedness of WordNet, but their work is limited to nouns only. 
[1]	In (McCarthy et al. , 2004), a method was presented to determine the predominant sense of a word in a corpus. 
[]	SVM) (Lee and Ng, 2002) or semi-supervised methods (ex. 
[1]	Although sense distribution data derived from SemCor can be more accurate than such information derived automatically (McCarthy et al. , 2004), in a given domain there will be words for which the SemCor frequency distributions are inappropriate or unavailable.
[1]	Furthermore, it is not possible to apply the powerful "one sense per discourse" property (Yarowsky, 1995) because there is no discourse in dictionaries. 
[]	Similarly, (Yarowsky, 1995) tested his WSD algorithm on a dozen words. 
[]	The interest data was first studied by (Bruce and Wiebe, 1994). 
[]	Unsupervised algorit~m~ such as (Yarowsky, 1995) have reported good accuracy that rivals that of supervised algorithms. 
[]	Let us first consider the use of decision lists, as proposed in Yarowsky (1994). 
[1]	Yarowsky (1995) proposes a method for word sense disambiguation, which is based on Monolingual Bootstrapping. 
[]	The sense marked with ** is defined in LDOCE but not used in Yarowsky (1992). 
[]	We investigated the one sense per discourse hypothesis (Gale et al., 1992b) in the context of machine translation. 
[]	In contrast, LEXAS uses supervised learning from tagged sentences, which is also the approach taken by most recent work on WSD, including (Bruce and Wiebe, 1994; Miller et al. , 1994; Leacock et al. , 1993; Yarowsky, 1994; Yarowsky, 1993; Yarowsky, 1992).
[]	The work of (Miller et al. , 1994; Leacock et al. , 1993; Yarowsky, 1992) used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques.
[]	Yarowsky (1992) used a thesaurus to collect training materials. 
[]	This corpus was first reported in (Ng and Lee, 1996), and it contains about 192,800 sense-tagged word occurrences of 191 most frequently occurring and ambiguous words of English. 
[]	In this paper, we used the WSD program reported in (Lee and Ng, 2002). 
[]	Syntactic Relations We adopt the same syntactic relations as (Lee and Ng, 2002). 
[]	SEMCOR corpus (Miller et al. , 1994) is one of the few currently available, manually sense annotated corpora for WSD. 
[]	More important is information beyond selectional preference, notably the wider context utilized by Yarowsky (1992). 
[]	A supervised algorithm based on this property is given in (Yarowsky, 1994). 
[1]	Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995).
[1]	Yarowsky (1995) has proposed a bootstrapping method for word sense disambiguation. 
[1]	Many different learning approaches have been used, including neural networks (Leacock et al. , 1993), probabilistic algorithms (Bruce and Wiebe, 1994; Gale et al. , 1992a; Gale et al. , 1995; Leacock et al. , 1993; Yarowsky, 1992), decision lists (Yarowsky, 1994), exemplar-based learning algorithms (Cardie, 1993; Ng and Lee, 1996), etc. In particular, Mooney (1996) evaluated seven state-of-the-art machine learning algorithms on a common data set for disambiguating six senses of the word "line".
[1]	Previous uses of this model include language modeling(Lau et al. , 1993), machine translation(Berger et al. , 1996), prepositional phrase attachment(Ratnaparkhi et al. , 1994), and word morphology(Della Pietra et al. , 1995).
[]	Further details may be found in Yarowsky (1992). 
[]	The line data was first studied by (Leacock et al. , 1993). 
[]	It has been shown that one sense per discourse property can improve the performance of bootstrapping algorithm (Li and Li, 2004; Yarowsky, 1995). 
[]	Our final partial tagger is a re-implementation of the algorithm developed by Yarowsky (1992).
[]	We also include verb-object syntactic relation as a feature, which is not used in (Yarowsky, 1994). 
