You should select [10] representative sentences! 

[1]	Shallow approaches to semantic processing are making large advances in the direction of efficiently and effectively deriving application relevant explicit semantic information from text (Pradhan et al., 2003; Gildea and Palmer, 2002; Pradhan et al., 2004; Gildea and Jurafsky, 2002; Xue and Palmer, 2004; Chen and Rambow, 2003; Carreras and Marquez, 2005; Moschitti, 2004; Moschitti et al., 2005; Diab et al., 2008).
[]	An important baseline study of this process has recently appeared in the literature (Gildea and Jurafsky, 2002). 
[]	Finally, as CoNLL 2005 has shown that the most important contribution relates on re-ranking predicate argument structures based on one single tree (Toutanova et al. , 2005) or several trees (Punyakanok et al. , 2005), we would like to use tree kernels for the re-ranking task. 
[]	(Gildea and Jurafsky, 2002) used the empirical probability of the set of proposed arguments as a prior distribution. 
[]	The impact of our head-word based scoring is analyzed in Table 3, which compares results when only the head word must be correctly identified (as in Table 2) and to results when both the beginning and end of the argument must be correctly identified in the sentence (as in Gildea and Palmer (2002)). 
[1]	Most approaches to the problem of SRL follow the Gildea and Jurafsky (2002) model. 
[]	A constituent-based system using Charniaks parser (Charniak, 2000). 
[]	Though several pruning algorithms have been raised (Xue and Palmer, 2004), the policies are all in global style. 
[]	The partial trees output by these systems were merged with the parse trees returned by (Charniak, 2000)s parser. 
[]	This approach was soon followed by other researchers (Surdeanu et al., 2003; Pradhan et al., 2004; Xue and Palmer, 2004), focus21 ing on improved sets of features, improved machine learning methods or both, and SRL became a shared task at the CoNLL 2004, 2005 and 2008 conferences1.
[]	We used a regularization parameter (option -c) equal to 1 and = 0.4 (see (Moschitti, 2004)). 
[]	For NomBank SRL fea140 Baseline Features (Pradhan et al. , 2005) b1 predicate: stemmed noun b2 subcat: grammar rule that expands the predicates parent b3 phrase type: syntactic category of the constituent b4 head word: syntactic head of the constituent b5 path: syntactic path from the constituent to the predicate b6 position: to the left or right of the predicate b11 first or last word/POS spanned by the constituent (b11FW, b11LW, b11FP, b11LP) b12 phrase type of the left or right sister (b12L, b12R) b13 left or right sisters head word/POS (b13LH, b13LP, b13RH, b13RP) b14 phrase type of parent b15 parents head word or its POS (b15H, b15P) b16 head word of the constituent if its parent has phrase type PP b17 head word or POS tag of the rightmost NP node, if the constituent is PP (b17H, b17P) b18 phrase type appended with the length of path b19 temporal keyword, e.g., Monday b20 partial path from the constituent to the lowest common ancestor with the predicate b21 projected path from the constituent to the highest NP dominating the predicate Baseline Combined Features (Xue and Palmer, 2004) b31 b1 & b3 b32 b1 & b4 b33 b1 & b5 b34 b1 & b6 Table 1: Baseline features for NomBank SRL tures, we use this set of more specific mappings to replace the morphological mappings based on WordNet. 
[1]	SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrase structure trees. 
[]	The alternative approach is to combine heuristic and machine-learning approaches (Xue and Palmer, 2004). 
[1]	Semantic role labeling based on predicate argument structure was first explored in detail by (Gildea and Jurafsky, 2002). 
[]	We also compared our proposed feature set against predicate/argument features (PAF) proposed by (Moschitti, 2004). 
[]	A related work is reported in (Gildea and Hockenmaier, 2003). 
[]	As mentioned by (Pradhan et al., 2004), argument identification plays a bottleneck role in improving the performance of a SRL system.
[1]	With the advent of supporting resources, SRL has become a well-dened task with a substantial body of work and comparative evaluation (see, among others, Gildea and Jurafsky [2002], Surdeanu et al.[2003], Xue and Palmer [2004], Pradhan et al.[2005a], the CoNLL Shared Task in 2004 and 2005, and Senseval-3 and SemEval-2007).The identication of event frames may potentially benet many natural language processing (NLP) applications, such as information extraction (Surdeanu et al.2003), question answering (Narayanan and Harabagiu 2004), summarization (Melli et al.2005), and machine translation (Boas 2002).Related work on classifying the semantic relations in noun phrases has also been encouraging for NLP tasks (Moldovan et al.2004; Rosario and Hearst 2004).
[1]	This corpus contains annotations of semantic PASs superimposed on the Penn Treebank (PTB) (Marcus et al. , 1993; Marcus et al. , 1994). 
[]	The error rate, 10.0%, is lower than that reported by Gildea and Palmer (2002), 17.2%. 
[]	Hence, the process is divided into framing and annotation (Palmer et al., 2005). 
[]	More details of this system can be found in Pradhan et al. , (2005). 
[1]	Gildea and Jurafsky (2002) presented a compact set of features across these three types, which has served as the core of most of the subsequent SRL work: (1) the phrase type, headword, and governing category of the constituent; (2) the lemma, voice, and subcategorization pattern of the verb; and (3) the left/right position of the constituent with respect to the verb, and the category path between them.Extensions to these features have been proposed in various directions.Exploiting the ability of some machine learning algorithms to work with very large feature spaces, some authors have largely extended the representation of the constituent and its context, including among others: rst and last words (and part-of-speech) in the constituent, bag-of-words, n-grams of part of speech, and sequence of top syntactic elements in the constituent.Parent and sibling constituents in the tree may also be codied with all the previous structural and lexical features (Pradhan et al.2005a; Surdeanu et al.2007).Other authors have designed new features with specic linguistic motivations.For instance, Surdeanu et al.(2003) generalized the concept of headword with the content word feature.They also used named entity labels as features.Xue and Palmer (2004) presented the syntactic frame feature, which captures the overall sentence structure using the verb predicate and the constituent as pivots.All these features resulted in a signicant increase in performance. 
[1]	Gildea and Jurafsky (2002) first tackled SRL as an independent task, which is divided into several sub-tasks such as argument identification, argument classification, global inference, etc. Some researchers (Xue and Palmer, 2004; Koomen et al., 2005; Cohn and Blunsom, 2005; Punyakanok et al., 2008; Toutanova et al., 2005; Toutanova et al., 2008) used a pipelined approach to attack the task.
[]	With very few exceptions (e.g. Collobert and Weston, 2007), published SRL methods have used some sort of syntactic structure as input (Gildea and Palmer, 2002; Punyakanok et al., 2008). 
[]	The two main resources are PropBank (Palmer et al., 2005) and FrameNet (Ruppenhofer et al., 2006). 
[1]	Given the variability in the sets of roles used across the computational resources, an important issue is the extent to which different role sets affect the SRL task, as well as subsequent use of the output in other NLP applications.Gildea and Jurafsky (2002) initiated this type of investigation by exploring whether their results were dependent on the set of semantic roles they used.To this end, they mapped the FrameNet frame elements into a set of abstract thematic roles (i.e., more general roles such as Agent, Theme, Location), and concluded that their system could use these thematic roles 149 Computational Linguistics Volume 34, Number 2 without degradation.Similar questions must be investigated in the context of PropBank, where the framesets for the verbs may have signicant domain-specic meanings and arguments due to the dependence of the project on WSJ data.Given the uncertainty in the linguistic status of semantic role lists, and the lack of evidence about which types of roles would be most useful in various NLP tasks, an important ongoing focus of attention is the value of mapping between the role sets of the different resources (Swier and Stevenson 2005; Loper, Yi, and Palmer 2007; Yi, Loper, and Palmer 2007). 
[]	Content words, which add informative lexicalized information different from the head word, were detected using the heuristics of (Surdeanu et al. , 2003). 
[]	The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006)4, we here extend it to nouns and prepositions. 
[]	Gildea and Jurafsky (2002) presented a compact set of features across these three types, which has served as the core of most of the subsequent SRL work: (1) the phrase type, headword, and governing category of the constituent; (2) the lemma, voice, and subcategorization pattern of the verb; and (3) the left/right position of the constituent with respect to the verb, and the category path between them.Extensions to these features have been proposed in various directions.Exploiting the ability of some machine learning algorithms to work with very large feature spaces, some authors have largely extended the representation of the constituent and its context, including among others: rst and last words (and part-of-speech) in the constituent, bag-of-words, n-grams of part of speech, and sequence of top syntactic elements in the constituent.Parent and sibling constituents in the tree may also be codied with all the previous structural and lexical features (Pradhan et al.2005a; Surdeanu et al.2007).Other authors have designed new features with specic linguistic motivations.For instance, Surdeanu et al.(2003) generalized the concept of headword with the content word feature.They also used named entity labels as features.Xue and Palmer (2004) presented the syntactic frame feature, which captures the overall sentence structure using the verb predicate and the constituent as pivots.All these features resulted in a signicant increase in performance.
[]	On the other hand, the previous researches (Gildea and Palmer, 2002; Punyakanok et al. , 2005) have also recognized the 74 
[]	(Xue and Palmer, 2004) or (Carreras and M`arquez, 2005). 
[]	This greedy combination method is very simple and has been adopted in previous research (Pradhan et al., 2005; M`arquez et al., 2005). 
[1]	Many research efforts utilize machine learning (ML) approaches; such as support vector machines (Moschitti et al. , 2004; Pradhan et al. , 2004), perceptrons (Carreras et al. , 2004), the SNoW learning architecture (Punyakanok et al. , 2004), EMbased clustering (Baldewein et al. , 2004), transformation-based learning (Higgins, 2004), memory-based learning (Kouchnir, 2004), and inductive learning (Surdeanu et al. , 2003).
