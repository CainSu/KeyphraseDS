Capturing
question
answer
dependencies
cast
straightforward
process
mapping
syntactic
trees
sets
binary
head
modifier
relationships
noted
(Collins
1996)
IBMs
Statistical
QA
(Ittycheriah
al
2001a)
system
probabilistic
model
trainable
Question-Answer
sentence
pairs
In
(Echihabi
Marcu
2003)
form
combining
strategies
advanced
proposed
(1)
knowledge-based
Q/A
implementation
based
syntactic/semantic
processing
combined
using
maximum-entropy
framework
(2)
statistical
noisy-channel
algorithm
(3)
pattern-based
approach
learn
Web
data
But
impossible
surface
text
patterns
following
(Ravichandran
Hovy
2002)
This
method
described
Ravichandran
(2002)
For
example
information
deployed
reformul+ate
questions
(Hermjakob
replace
syntactically
similar
ones
(Lin
Pantel
2001)
lexical
ontologies
Wordnet1
synonyms
words
(Burke
1997
2000
Prager
2001
Harabagiu
machine
translation
(SMT)
models
trained
question-answer
rank
candidate
answers
according
probabilities
(Berger
Echihabi
2003
Soricut
Brill
2006)
2003))
(4)
constraint
satisfaction
auxiliary
provide
constrain
individual
(cf
To
evaluate
learning
AQUAREA$
development
set
stories
tested
test
past
reading
comprehension
task
(Hirschman
1999
Charniak
Riloffand
Thelen
Wang
2000)
Naturally
current
answering
related
Our
considers
features
Feature
Set
(FS1)
reported
(Gildea
Palmer
Jurafsky
(FS2)
novel
introduced
paper
Several
attempt
extend
WordNet
additional
semantic
(Moldovan
Rus
Snow
2006
Suchanek
2007
Clark
2008)
The
LCC
Logic
Prover
establish
connection
passage
Gildea
describe
FrameNet
project
automatically
assign
roles
As
guideline
interpreting
results
8167
observations
threshold
significance
05
10%
absolute
difference
performance
birth
person
typically
expressed
phrases
<name>
born
<birthyear>
(<birthyear><deathyear>)
We
developed
web
supervised
identifier
defined
theme
target
goal
boundaries
(Baker
Another
natural
language
deployment
SMT
(re)ranking
assumed
contained
FAQ
pages
retrieved
baseline
systems
load
COGEX
logic
prover
operates
reductio
ad
absurdum
Hs
negated
Ts
predicates
1999)
initiated
series
accuracy
363%
Narayanan
(2004)
stress
importance
complex
However
context
factual
conceptual
categories
helpful
instead
semantically
classify
earlier
TREC
(Singhal
Ittycheriah
identify
corpus-based
received
lots
attention
team
taking
Tracks
competitive
stage
(Soubbotin
Soubbotin
2002
By
implementing
own
version
publicly
available
Collins
parser
learned
dependency
enables
parse
relations
head-word
constituent
sibling-words
prior
type
sources
computation
specific
rlifFerent
independent
effort
MITRE
investigated
Many
studies
focused
discriminative
predict
function
matching
(set
sentences)
namely
q/a
eg
(Ng
Hickl
Shen
Klakow
Celikyilmaz
2009)
predicate
levels
probability
lattice
hence
scalability
unknown
limited
Although
semantics-poor
techniques
pattern
methods
successful
factoid
tasks
require
consideration
meaning
convert
achieve
resolve
sparsity
employed
backoff
solution
combines
field
pre-defined
relation
proved
fairly
reliable
particularly
queries
(Brill
2004)
select
passages
experiments
applied
PropBank
corpus
previous
predicting
argument
1998)
Data
collected
4500
English
published
USC
(Hovy
500
manually
constructed
rare
classes
894
10
serves
These
labeled
hierarchy
Examples
22
bag-of-words
fails
abound
inQAliterature
borrow
(2003)
Such
(eg
president
George
Bush)
productive
occur
40
times
Hearst
(1992)
evaluates
Quarc
DeepRead
domain
dependent
resource
intensive
solely
employs
database
explored
extracting
hyponym
Berland
(1999)
extract
part-of
built
Question
Answering
help
desirable
copy
add
list
identical
dictionary
word
iw
GIZA
(Al-Onaizan
package
implements
IBM
(Brown
1993)
train
maps
flattened
obtained
cut
procedure
Section
31
referred
10-90
rule
Recently
pioneering
approaches
construct
components
scratch
applying
training
2001a)(Ittycheriah
2001b)(Ng
(Pasca
Harabagiu)(Suzuki
2002)(Suzuki
215
Table
Number
Questions
Types
CRL
Example
1-9
74
AWARD
CRIME
OFFENSE
10-50
32
PERCENT
N
PRODUCT
YEAR
PERIOD
51-100
COUNTRY
COMPANY
GROUP
100-300
PERSON
DATE
MONEY
Total
115
(Zukerman
Horvitz
2001)(Sasaki
(QA)
cited
obvious
beneficiary
12
role
labeling
2005
nd
argmax
pC
H(p)
means
p(y|x)
maximizes
entropy
Similarly
Murdock
Croft
(2005)
adopted
simple
1990
Brown
propose
study
develop
kernel
operate
Support
Vector
Machines
determining
optimal
compare
Maximum
Entropy
combinations
Open-domain
(Lehnert
1986
Light
story
directions
selects
alternative
ontology
preference
particular
examined
advantage
textual
as)
common
class
acquisition
document
retrieval
(Dumais
query
expansion
(Yang
structured
extraction
validation
(Magnini
keys
created
developers
Being
inspired
success
noisy-channel-based
applications
diverse
speech
recognition
(Jelinek
1997)
tagging
(Church
1988)
Lafferty
summarization
(Knight
noisy
channel
Systems
addressing
opportunity
explore
structures
(Narayanan
Answer
types
determined
classification
rules
Li
Roth
One
address
question-to-answer
transformations
Riezler
2007)
(Fellbaum
popular
variety
QA-related
ranging
axiom-based
reasoning
scoring
(Paranjpe
filtering
(Leidner
Moldovan
transformed
forms
determine
(ALF)
entails
form(QLF)
computed
Model
P(Q|A)
product
display
qQ
P(q|A)
(1)Pml(q|A)+Pml(q|C)
Pml(q|A)
summation
aA
(T(q|a)Pml(a|A))
(5)
term
generated
A
smoothed
entire
collection
C
Pml(q|C)
Porting
involves
parse-tree
pruning
heuristics
(the
deterministic
steps
replacing
table
monolingual
simply
encodes
identity
Automatic
derivation
appealing
description
ME
representation
converts
a1
a0
metric
originally
Next
Pr
F
ip
Pfr
While
web-based
previously
literature
modeled
relationship
(correct)
terms
relevance
tried
approximate
deeper
phenomena
involved
answerhood
Recent
witnessed
significant
progress
developing
automatic
identification
conveyed
sentential
constituents1
collectively
shallow
parsing
due
availability
resources
(Fillmore
(Palmer
2005)
realization
real
world
corpora
It
note
frames
generalizing
frame
found
frequently
share
structure
distributions
maximum
formulation
consists
human
judgments
feature
designed
capture
Cha_niak
Riloff
computations
met129
rics
metrics
correlate
Wordnets
wide
direct
indirect
axioms
extracted
inference
via
constraints
ANSWER
SELECTION
modules
trying
prove
correct
giving
weight
produced
summing
heuristic
(Radev
latter
candidates
larger
exactly
match
generate
score
fewer
agent
takes
adapted
etal
Scenario
knowledge
included
axiomatic
transformation
