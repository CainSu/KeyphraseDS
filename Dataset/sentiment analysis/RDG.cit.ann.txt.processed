Sentiment classification is a well studied problem (Wiebe 2000 Pang et al 2002 Turney 2002) and in many domains users explicitly 1We use the term aspect to denote properties of an object that can be rated by a user as in Snyder and Barzilay (2007) 
According to Choi and Cardie (2008) voting algorithms that recognize content-word negators achieve a competitive performance so we will use a variant of it for simplicity 
Recognizing the subjective character and polarity of words phrases or sentences has been addressed by many authors including (Turney 2003 Riloff et al  2003 Wiebe 2000 Hatzivassiloglou and McKeown 1997) 
We also note that Turney (2002) found movie reviews to be the most 2Indeed although our choice of title was completely independent of his our selections were eerily similar 
Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney 2002 Wilson et al 2005 Pang and Lee 2008) 
Automatic identification of subjective content often relies on word indicators such as unigrams (Pang et al 2002) or predetermined sentiment lexica (Wilson et al 2005) 
All reviews were automatically preprocessed to remove both explicit rating indicators and objective sentences the motivation for the latter step is that it has previously aided positive vs negative classi cation (Pang and Lee 2004) 
The work most similar in spirit to ours that of Turney (2002) 
Some researchers have also recently applied hidden variable models to sentiment analysis but they were focused on classifying either phrase-level (Choi and Cardie 2008) or sentence-level polarity (Nakagawa et al 2010) 
Pang and Lee (2005) treat sentiment analysis as an ordinal ranking problem 
These results hold true both when the lexicons are used in conjunction with string matching to classify sentences and when they are included within a contextual classifier framework (Wilson et al 2005) 
The span detector is based on conditional random fields (CRFs) (Lafferty McCallum and Pereira 2001) which is a structured prediction learning framework common in sub-sentential natural language processing tasks including sentiment analysis (Choi and Cardie 2007 McDonald et al 2007) The approach presented here resembles work by Morante and Daelemans (2009) who used IGTree to predict negation cues and a CRF metal earner that combined input from k-nearest neighbor classification a support vector machine and another underlying CRF to predict the scope of negations within the BioScope corpus 
There has been a large and diverse body of research in opinion mining with most research at the text (Pang et al 2002 Pang and Lee 2004 Popescu and Etzioni 2005 Ounis et al 2006) sentence (Kim and Hovy 2005 Kudo and Matsumoto 2004 Riloff et al 2003 Yu and Hatzivassiloglou 2003) or word (Hatzivassiloglou and McKeown 1997 Turney and Littman 2003 Kim and Hovy 2004 Takamura et al 2005 Andreevskaia and Bergler 2006 Kaji and Kitsuregawa 2007) level 
Recently a variety of studies have been reported on sentiment classification at different levels word level (Esuli and Sebastiani 2005) phrase level (Wilson et al 2009) sentence level (Kim and Hovy 2004 Liu et al 2005) and document level (Turney 2002 Pang et al 2002) 
For example Yu and Hatzivassiloglou (2003) separated facts from opinions and assigned polarities only to opinions 
A majority of the clues were collected as part of work reported in Riloff and Wiebe (2003) 
For example Hatzivassiloglou and McKeown (1997) labeled adjectives as positive or negative relying on semantic orientation 
That is why Liu and Seneff (2009) suggest a compositional model in which for individual adjectives and adverbs (the latter include negations) a prior rating score encoding their intensity and polarity is estimated from pros and cons of on-line reviews 
In the future work we will integrate the subjectivity summarization strategy (Pang and Lee 2004) to help discard noisy objective sentences 
Another area for future work is to empirically compare PMI-IR and the algorithm of Hatzivassiloglou and McKeown (1997) 
In each case OPINE makes use of local constraints on label assignments (eg  conjunctions and disjunctions constraining the assignment of SO labels to words (Hatzivassiloglou and McKeown 1997)) 
Sentence and phrase level sentiment analysis involves a systematic examination of texts such as blogs reviews and news reports for positive negative or neutral emotions (Wilson et al  2005 Grefenstette et al  2004) 
Similar to eg (Pang et al  2002) we use a Naive Bayes algorithm trained on word features cooccurring with the subjective and the objective classifications 
The approaches presented in the previous section (Polanyi and Zaenen 2004 Kennedy and Inkpen 2005 Wilson et al 2005) can be considered as the works pioneering negation modeling in sentiment analysis 
For these algorithms already a low-level representation using bag of words is fairly effective (Pang et al 2002) 
As mentioned previously there are a wide variety of verbs and adverbs that play such a role and recent studies have investigated methods for identifying them (Choi and Cardie 2008 Danescu-Niculescu-Mizil et al 2009) 
Subjective phrases are used by (Turney 2002 Pang and Vaithyanathan 2002 Kushal et al  2003 Kim and Hovy 2004) and others in order to classify reviews or sentences as positive or negative 
A number of researchers have explored learning words and phrases with prior positive or negative polarity (another term is semantic orientation) (eg  (Hatzivassiloglou and McKeown 1997 Kamps and Marx 2002 Turney 2002)) 
The polarity shifter and negation phrase lists have been taken from the Opinion Finder system (Wilson et al 2005) 
Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentiment bearing words 
Indeed recent work has shown that benefits can be made by first separating facts from opinions in a document (eg Yu and Hatzivassiloglou (2003)) and classifying the polarity based solely on the subjective portions of the document (eg  Pang and Lee (2004)) 
Researchers have focused on learning adjectives or adjectival phrases (Turney 2002 Hatzivassiloglou and McKeown 1997 Wiebe 2000) and verbs (Wiebe et al  2001) but no previous work has focused on learning nouns 
Sentiment analysis research has been performed to distinguish the authors polarity (sentiment orientation) on certain topics from document level (Turney 2002 Pang et al 2002 Dave et al 2003) to sentence-level (Hu and Liu 2004 498 Kim and Hovy 2004) 
Examples are movie reviews (Pang and Lee 2005) opinions (Wiebe et al 2005) customer reviews (Ding et al 2008) or multiple aspects of restaurants (Snyder and Barzilay 2007) 
Automatic subjectivity analysis would also be useful to perform flame recognition (Spertus 1997 Kaufer 2000) e-mail classification (Aone Ramos-Santacruze and Niehaus 2000) intellectual attribution in text (Teufel and Moens 2000) recognition of speaker role in radio broadcasts (Barzialy et al 2000) review mining (Terveen et al 1997) review classification (Turney 2002 Pang Lee and Vaithyanathan 2002) style in generation (Hovy 1987) and clustering documents by ideological point of view (Sack 1995) 
To compile the lexicon we began with a list of subjectivity clues from (Riloff and Wiebe 2003) 
Past studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy 2004 Esuli and Sabastiani 2009 Blair-Goldensohn et al 2008 Rao and Ravichandran 2009) 
In fact it has already been established that sentence level classification can improve document level analysis (Pang and Lee 2004) 
Much of the work in sentiment analysis in the computational linguistics domain has focused either on short segments such as sentences (Wilson et al  2005) or on longer documents with an explicit polarity orientation like movie or product reviews (Turney 2002) 
Instead of document level sentiment classification (Wilson et al 2005) analyze the contextual polarity of phrases and incorporate many well designed features including dependency trees 
For determining whether an opinion sentence is positive or negative we have used seed words similar to those produced by (Hatzivassiloglou and McKeown 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney 2002) 
The use of multiple text classifiers by Wiebe and colleagues (Wilson et al  2005 Wiebe et al  2004) for various kinds of sentiment classification can also be viewed as a sentence level technique for analyzing appraisal expressions 
Much of this work has utilized the fundamental concept of semantic orientation (Turney 2002) however sentiment analysis still lacks a unified field theory 
Hatzivassiloglou and McKeown (1997) proposed a supervised algorithm to determine the semantic orientation of adjectives 
Sentiment detection and classification has received considerable attention recently (Pang et al  2002 Turney 2002 Goldberg and Zhu 2004) 
Turney (2002) determines the sentiment orientation of a document by calculating point-wise mutual information between the words in the document and the seed words of excellent and poor 
Each document D therefore is represented as a bag-ofwords feature vector D = braceleftbigw1w2w|V |bracerightbig where |V| is the size of the vocabulary (ie the number of unique words) and wi i = 1|V | is the weight of term i in document D Despite the significant attention that sentiment analysis has received in recent years the best accuracy without using complex features (Mullen and Collier 2004 Whitelaw et al 2005) or additional human annotations (Zaidan et al 2007) is achieved by employing a binary weighting scheme (Pang et al 2002) where wi = 1if tfi > 0 and wi = 0if tfi = 0 where tfi is the number of times that term i appears in document D (henceforth raw term frequency) and utilizing a SVM classifier 
Moreover the assigned tag applies to the whole blog post while a finer grained sentiment extraction is needed (McDonald et al 2007) 
Since adjectives have been a focus of previous work in sentiment detection (Hatzivassiloglou and Wiebe 2000 Turney 2002)13 we looked at the performance of using adjectives alone 
This approach outperformed competing methods when it considered relatively small numbers of labeled samples from the four-category movie review dataset (Pang and Lee 2005) 
Some of the work is not related to discourse at all (eg lexical similarities (Takamura et al 2007) morpho syntactic similarities (Popescu and Etzioni 2005) and word-based measures like TFIDF (Goldberg and Zhu 2006)) 
On the other hand it would be interesting to evaluate PMI-IR on the collection of 1336 hand-labeled adjectives that were used in the experiments of Hatzivassiloglou and McKeown (1997) 
Interestingly previous sentiment analysis research found that a minimum-cut formulation for the binary subjective/objective distinction yielded good results (Pang and Lee 2004) 
Sentiment analysis can be dependently or independently done from subjectivity detection although Pang and Lee (2004) state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter 
We begin by describing a graph propagation framework inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy 2004 Hu and Liu 2004 Esuli and Sabastiani 2009 BlairGoldensohn et al 2008 Rao and Ravichandran 2009) 
This approach builds a subjectivity-annotated corpus for the target language through projection and then trains a statistical classifier on the resulting corpus (numerous statistical classifiers have been trained for subjectivity or sentiment classification eg (Pang et al  2002 Yu and Hatzivassiloglou 2003)) 
Generally the MCST-SVM is competitive against all the classifiers presented in (Pang and Lee 2005) and in some cases significantly outperforms these methods 
The work of (Polanyi and Zaenen 2006 Choi and Cardie 2008) focuses on manually constructing several lexica and rules for both polar words and related content-word negators such as prevent cancer where prevent reverses the negative polarity of cancer 
With this model we can provide not only qualitative textual summarization such as good food and bad service but also a numerical scoring of sentiment ie how good the food is and how bad the service is 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee 2004 2005 Gamon et al 2005 Popescu and Etzioni 2005 Liu et al 2005 Zhuang et al 2006 Kim and Hovy 2006) 
Content-word negators are words that are not function words but act semantically as negators (Choi and Cardie 2008)3 Although it is possible to artificially construct a very convoluted sentence with lots of negations it is unlikely for multiple layers of negations to appear very often in natural language (Pickett et al 
For instance instead of representing the polarity of a term using a binary value Mullen and Collier (2004) use Turneys (2002) method to assign a real value to represent term polarity and introduce a variety of numerical features that are aggregate measures of the polarity values of terms selected from the document under consideration 
Thus the method we investigate can be seen as a combination of methods for propagating sentiment across lexical graphs and methods for building sentiment lexicons based on distributional characteristics of phrases in raw data (Turney 2002) 
As a special task of text classification sentiment classification aims to classify a text according to the expressed sentimental polarities of opinions such as thumb up or thumb down on the movies (Pang et al 2002) 
Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs which is denoted as the semantic oriented method 
The Pittsburgh subjectivity lexicon (PSL) (Wilson et al 2005) which draws from the General Inquirer and other sources also has semantic orientation labels but only for about 8000 words 
Choi and Cardie (2008) address a sentiment analysis task by using a heuristic decision process based on wordlevel intermediate variables to represent polarity 
We also cannot use prior graph construction methods for the document level (such as physical proximity of sentences used in Pang and Lee (2004)) at the word sense level 
Subjectivity is defined as the linguistic expression of somebodys opinions sentiments emotions evaluations beliefs and speculations (Wiebe 1994) 
Such inference rules are very reminiscent of polarity modification features (Wilson et al 2005) as a negative polar expression is modified by positive polar expression 
Riloff and Wiebe (2003) describe a bootstrapping method to learn subjective extraction patterns that match specific syntactic templates using a high-precision sentence-level subjectivity classifier and a large unannotated corpus 
A common approach is to use a sentiment labelled lexicon to score sentences (Hatzivassiloglou and McKeown 1997 Turney 2002 Yu and Hatzivassiloglou 2003) 
Comparison with Pang and Lee (2005) Figure 2 compares the performance of the algorithms presented in (Pang and Lee 2005) against the performance of the best MCST-SVM variant which employs feature culling and uses the Tanimoto coefficient to compute inter-class similarity (Section 42) 
There have been attempts on tackling this so-called document-level subjectivity classification task with very encouraging results (see Yu and Hatzivassiloglou (2003) and Wiebe et al 
We use linear SVMs which have been shown to be effective text classifiers (Pang et al 2002 Pang and Lee 2005) and set the SVM parameters to match those used in (Pang and Lee 2005)1 Figure 1 contrasts 1SVMs are implemented using the C/C++ library liblinear a variant of libsvm (Chang and Lin 2001) 
Most prior work on the speci c problem of categorizing expressly opinionated text has focused on the binary distinction of positive vs negative (Turney 2002 Pang Lee and Vaithyanathan 2002 Dave Lawrence and Pennock 2003 Yu and Hatzivassiloglou 2003) 
Research suggests that creating a general sentiment classifier is a difficult task and existing approaches are highly topic dependent (Engstrom 2004 Gamon and Aue 2005 Blitzer et al 2007) 
In this work we focus on explicit negation mentions also called functional negation by Choi and Cardie (2008) 
Like several previous work (eg  Mullen and Collier (2004) Pang and Lee (2004) Whitelaw et al 
The fine-grained opinion corpus used in (Wilson et al 2005 Wilson et al 2009) and all the resources necessary to replicate the features used in these experiments are also publicly available3 
In terms of relative performance Naive Bayes tends to do the worst and SVMs tend to do the best although the 12http//wwwenglishbhamacuk/stafi/oliver/software/tagger/indexhtm 13Turneys (2002) unsupervised algorithm uses bigrams containing an adjective or an adverb 
When modeling only positive and negative labels for sentiment negators are generally treated as flipping the polarity of the adjective it modifies (Choi and Cardie 2008 Nakagawaetal 2010) 
It is intuitive that this should also be valid when polarities enter the 101 picture this was also noted by Choi and Cardie (2008) 
(Hatzivassiloglou and McKeown 1997) describes a method for identifying the semantic orientation of words for example that beautiful expresses positive sentiments 
While most of the works on sentiment analysis focus on full text some works address sentiment analysis in the phrasal and sentence level see (Yu and Hatzivassiloglou 2003 Wilson et al 2005 McDonald et al 2007 Titov and McDonald 2008a Titov and McDonald 2008b Wilson et al 2009 Tsur et al 2010) among others 
Furthermore these systems have tackled the problem at different levels of granularity from the document level (Pang et al  2002) sentence level (Pang and Lee 2004 Mao and Lebanon 2006) phrase level (Turney 2002 Choi et al  2005) as well as the speaker level in debates (Thomas et al  2006) 
For example authors of movie reviews often devote large sections to (largely objective) descriptions of the plot (Pang and Lee 2004) 
Much of the work on this problem has considered binary sentiment polarity (positive or negative) at granularity levels ranging from sentences (Yu and Hatzivassiloglou 2003 Mao and Lebanon 2006 McDonald et al 2007) to documents (Wilson et al 2005 Allison 2008) 
Choi and Cardie (2008) for example propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (ie out of context) polarity of the words in the phrase and the (correct) phrase-level polarity 
Turney (2002) used collocation with excellent or poor to obtain positive and negative clues for document classification 
Automatic opinion recognition involves a number of related tasks such as identifying expressions of opinion (eg Kim and Hovy (2005) Popescu and Etzioni (2005) Breck et al 
Automatic approaches to creating a semantic orientation lexicon and more generally approaches for word-level sentiment annotation can be grouped into two kinds (1) those that rely on manually created lexical resources most of which use WordNet (Strapparava and Valitutti 2004 Hu and Liu 2004 Kamps et al 2004 Takamura et al 2005 Esuli and Sebastiani 2006 An1http//wwwwjhharvardedu/ inquirer 599 dreevskaia and Bergler 2006 Kanayama and Nasukawa 2006) and (2) those that rely on text corpora (Hatzivassiloglou and McKeown 1997 Turney and Littman 2003 Yu and Hatzivassiloglou 2003 Grefenstette et al 2004) 
Much work on sentiment analysis classifies documents by their overall sentiment for example determining whether a review is positive or negative (eg  (Turney 2002 Dave et al  2003 Pang and Lee 2004 Beineke et al  2004)) 
This idea is similar to that of (Kim and Hovy 2004) and (Hu and Liu 2004) but instead of using a window of size k or the output of a noun phrase chunker OPINE takes advantage of the syntactic dependencies computed by the MINIPAR parser 
Another approach taken by Choi and Cardie (2008) and Somasundaran et al 
They introduced features based on Osgoods Theory of Semantic Differentiation (Osgood 1967) using WordNet to derive the values of potency activity and evaluative of adjectives and Turneys semantic orientation (Turney 2002) 
Kim and Hovy (2004) select candidate sentiment sentences and use word-based sentiment classifiers to classify unseen words into a negative or positive class 
To generate the initial explanations one can use an off-theshelf sentiment classifier such as OpinionFinder2 (Wilson et al 2005) 
Following standard sentiment ranking approaches (Wilson et al 2004 Pang and Lee 2005 Goldberg and Zhu 2006 Snyder and Barzilay 2007) we employ ordinary linear regression to independently map bag-of-words representations into predicted aspect ranks 
Hatzivassiloglou and McKeown (1997) use a four-step supervised learning algorithm to infer the semantic orientation of adjectives from constraints on conjunctions 1 
In this study we look at the problem of aspect based sentiment summarization (Hu and Liu 2004a Popescu and Etzioni 2005 Gamon et al 2005 Nikos Fine Dining Food 4/5 Best fish in the city Excellent appetizers Decor 3/5 Cozy with an old world feel Too dark Service 1/5 Our waitress was rude Awful service Value 5/5 Good Greek food for the $ Great price! Figure 1 An example aspect-based summary 
Sentiment analysis is often considered in the context of the following two tasks sentiment extraction given a set of textual documents identify phrases clauses sentences or entire documents that express attitudes and determine the polarity of these attitudes (Kim and Hovy 2004) and sentiment retrieval given a topic (and possibly a list of documents relevant to the topic) identify documents that express attitudes toward this topic (Ounis et al 2007) 
Most of the work has focused on analyzing the content of movie or general product reviews but there are also applications to other domains such as debates (Thomas et al 2006 Lin et al 2006) news (Devitt and Ahmad 2007) and blogs (Ounis et al 2008 Mishne 2005) 
Graph-based algorithms for classification into subjective/objective or positive/negative language units have been mostly used at the sentence and document level (Pang and Lee 2004 Agarwal and Bhattacharyya 2005 Thomas et al 2006) instead of aiming at dictionary annotation as we do 
Pang and Riloff (2005) and Yu and Hatzivassiloglou (2003) trained sentence-level subjectivity classifiers and proved that performing sentiment analysis targeting selected subjective sentences only gets higher results 
Admittedly the high accuracy achieved using such a simple set of features is somewhat surprising although it is consistent with previous results on document-level subjectivity classification in which accuracies of 94-97% were obtained (Yu and Hatzivassiloglou 2003 Wiebe et al  2004) 
Some work identifies inflammatory texts (eg  (Spertus 1997)) or classifies reviews as positive or negative ((Turney 2002 Pang et al  2002)) 
Many subjectivity and sentiment analysis tools rely on manually or semi-automatically constructed lexicons (Yu and Hatzivassiloglou 2003 Riloff and Wiebe 2003 Kim and Hovy 2006) 
We construct our lexicon using graph propagation techniques which have previously been investigated in the construction of polarity lexicons (Kim and Hovy 2004 Hu and Liu 2004 Esuli and Sabastiani 2009 Blair-Goldensohn et al 2008 Rao and Ravichandran 2009) 
Next we learn our polarity classifier using positive and negative reviews taken from two movie 611 review datasets one assembled by Pang and Lee (2004) and the other by ourselves 
Turney (2002) showed that it is possible to use only a few of those semantically oriented words (namely excellent and poor) to label other phrases co-occuring with them as positive or negative 
Intensifier_Dic en  244 intensifier terms were collected from the feature file intensifiers2tff used in the work (Wilson et al 2005a Wilson et al 2005b) 
In particular they have been an essential ingredient for fine grained sentiment analysis (eg Kim and Hovy (2004) Kennedy and Inkpen (2005) Wilson et al 
Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it either positive or negative often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown 1997 Wiebe 2000 Turney 2002) 
Typical approaches to the rating scale problem include standard k-way classifiers eg (Pang and Lee 2005) 
Some of this work focuses on classifying the semantic orientation of individual words or phrases using linguistic heuristics or a pre-selected set of seed words (Hatzivassiloglou and McKeown 1997 Turney and Littman 2002) 
Previous work on determining the semantic orientation of adjectives has used a complex algorithm that does not readily extend beyond isolated adjectives to adverbs or longer phrases (Hatzivassiloglou and McKeown 1997) 
One set consists of the previously described 657 positive and 679 negative adjectives (Hatzivassiloglou and McKeown 1997) 
Note that we select sentiment terms as those appear in the sentiment lexicon provided by MPQA project (Wilson et al 2005) 
On sentence-level polarity classification their scope model is compared with a simple negation scope using a fixed window size (similar to the negation feature in (Wilson et al 2005)) the text span until the first occurrence of a polar expression following the negation word the entire sentence The proposed method consistently outperforms the simpler methods proving that the incorporation of linguistic insights into negation modeling is meaningful 
As a result the problem of opinion mining has seen increasing attention over the last three years from (Turney 2002 Hu and Liu 2004) and many others 
Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs which is denoted as the semantic oriented method 
Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text 
After this conversion we had 1000 positive and 1000 negative examples for each domain the same balanced composition as the polarity dataset (Pang et al  2002) 
We wish to study opinion in general our work most closely resembles that of (Yu and Hatzivassiloglou 2003) 
We created 14 feature sets representing some classes from (Levin 1993 Ballmer and Brennenstuhl 1981) some Framenet lemmas with frame element experiencer (Baker et al  1998) adjectives manually annotated for polarity (Hatzivassiloglou and McKeown 1997) and some subjectivity clues listed in (Wiebe 1990) 
A subsequent innovation was the detection and removal of the objective parts of documents and the application of a polarity classifier on the rest (Pang and Lee 2004) 
Choi and Cardie (2008) also focus on the expression-level polarity classification but their evaluation setting is not as practical as ours in that they assume the inputsare guaranteed to be either strongly positive or negative 
Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase 
Sentiment analysis includes a variety of different problems including sentiment classification techniques to classify reviews as positive or negative based on bag of words (Pang et al  2002) or positive and negative words (Turney 2002 Mullen and Collier 2004) classifying sentences in a document as either subjective or objective (Riloff and Wiebe 2003 Pang and Lee 2004) identifying or classifying appraisal targets (Nigam and Hurst 2004) identifying the source of an opinion in a text (Choi et al  2005) whether the author is expressing the opinion or whether he is attributing the opinion to someone else and developing interactive and visual opinion mining methods (Gamon et al  2005 Popescu and Etzioni 2005) 
Yu and Hatzivassiloglou (2003) Kim and Hovy (2004) Hu and Liu (2004) and Grefenstette et al 
However recentwork (Taboada et al 2011 Liu and Seneff 2009) suggests that the effect of the negator when ordinal sentiment scores are employed is more akin to dampening the adjectives polarity rather than flipping it 
Automatic subjectivity analysis methods have been used in a wide variety of text processing applications such as tracking sentiment timelines in online forums and news (Lloyd et al  2005 Balog et al  2006) review classification (Turney 2002 Pang et al  2002) mining opinions from product reviews (Hu and Liu 2004) automatic expressive text-to-speech synthesis (Alm et al  2005) text semantic analysis (Wiebe and Mihalcea 2006 Esuli and Sebastiani 2006) and question answering (Yu and Hatzivassiloglou 2003) 
The dataset used for the experiments in (Pang et al 2002 Ng et al 2006) has been established as a popular benchmark dataset for sentiment analysis and is publicly available1 
Turneys (2002) work on classiflcation of reviews is perhaps the closest to ours2 He applied a speciflc unsupervised learning technique based on the mutual information between document phrases and the words \excellent" and \poor" where the mutual information is computed using statistics gathered by a search engine 
We ignored low-intensity phrases similar to (Choi and Cardie 2008 Nakagawa et al 2010) 
We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy 2004 Hu and Liu 2004 Esuli and Sabastiani 2009 Blair-Goldensohn et al 2008 Rao and Ravichandran 2009) 
In addition among the supervised classifiers SVM classifier performs the best in most products which is consistent with the previous research (Pang et al 2002) 
Starting with the Romanian lexicon we developed a lexical classifier similar to the one introduced by (Riloff and Wiebe 2003) 
For words that came from positive and negative word lists (General-Inquirer 2000 Hatzivassiloglou and McKeown 1997) we largely retained their original polarity either positive or negative 
Other document-level sentiment work includes (Turney 2002 Dave et al 2003 Beineke et al 2004 Pang and Lee 2004) 
Yu and Hatzivassiloglou (2003) provide methods for sentence level analysis and for determining whether a document is subjective or not but do not combine these two types of algorithms or consider document polarity classification 
The second six columns of Table 4 shows the performance of each lexicon as the core of a contextual classifier (Wilson et al 2005) 
While other systems such as (Hu and Liu 2004 Turney 2002) have addressed these tasks to some degree OPINE is the first to report results 
Review texts are automatically filtered to leave only subjective sentences (motivated by the results described in (Pang and Lee 2004)) the mean number of words per review in each subjective filtered sub-corpus is 435 374 455 and 292 respectively 
The former were based on the General Inquirer lexicon (Wilson et al 2005) the MontyLingua part-of-speech tagger (Liu 2004) and co-occurrence statistics of words with a set of predefined reference words 
Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects and builds a set of sentiment predictors 
But a crucial advantage specific to the utilization of a minimum-cut-based approach is that we can use maximum-flow algorithms with polynomial asymptotic running times and near-linear running times in practice to exactly compute the minimum cost cut(s) despite the apparent intractability of the optimization problem (Cormen Leiserson and Rivest 1990 Ahuja Magnanti and Orlin 1993)2 In contrast other graph-partitioning problems that have been previously used to formulate NLP classification problems3 are NP-complete (Hatzivassiloglou and McKeown 1997 Agrawal et al  2003 Joachims 2003) 
For example (Pang et al  2002) collected reviews from a movie database and rated them as positive negative or neutral based on the rating (eg  number of stars) given by the reviewer 
The approach is based on the hypothesis that positive words co-occur more than expected by chance and so do negative words this hypothesis was validated at least for strong positive/negative words in (Turney 2002) 
The acquisition of clues is a key technology in these research efforts as seen in learning methods for document-level SA (Hatzivassiloglou and McKeown 1997 Turney 2002) and for phrase level SA (Wilson et al 2005 Kanayama and Nasukawa 2006) 
Some existing resources contain lists of subjective words (eg  Levins desire verbs (1993)) and some empirical methods in NLP have automatically identified adjectives verbs and N-grams that are statistically associated with subjective language (eg  (Turney 2002 Hatzivassiloglou and McKeown 1997 Wiebe 2000 Wiebe et al  2001)) 
For instance one can formulate the sentence extraction task as a sequence labeling problem similar to (McDonald et al 2007) or use a more expressive graphical model such as in (Pang and Lee 2004 Thomas et al 2006) 
In order to compare our approach to other methods we also show results on commonly used sentiment datasets movie reviews4 (MR) (Pang and Lee 2005) and opinions5 (MPQA) (Wiebe et al 2005)We give statistical information on these and the EP corpus in Table 1 
Recent computational work either focuses on sentence subjectivity (Wiebe et al 2002 Riloff et al 2003) concentrates just on explicit statements of evaluation such as of films (Turney 2002 Pang et al 2002) or focuses on just one aspect of opinion eg (Hatzivassiloglou and McKeown 1997) on adjectives 
Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text 
Strictly speakingnegator is nota valuefor polaritybutwe include them inour lexicon because valence shiftersor negators have been shown to play an important role for sentiment analysis (eg Polanyi and Zaenen (2004) Moilanen and Pulman (2007) Choi and Cardie (2008)) 
Others such as Turney (2002) Pang and Vaithyanathan (2002) have examined the positive or negative polarity rather than presence or absence of affective content in text 
Sentiment analysis involves determining the opinions and private states (beliefs emotions speculations and so on) of the speaker (Wiebe 1994) 
The lexicons are generated from manually selected seeds for a broad domain such as Health or Business following an approach similar to (Kim and Hovy 2004) 
This also partially explains the effectiveness of bigrams and trigrams for this task as stated in (Ng et al 2006) 
First even when sentiment is the desired focus researchers in sentiment analysis have shown that a two-stage approach is often beneficial in which subjective instances are distinguished from objective ones and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou 2003 Pang and Lee 2004 Wilson et al  2005 Kim and Hovy 2006) 
Compared to methods that use a cascaded approach (eg Pang and Lee (2004)) our approach is more robust to errors in the lower-level subtask due to being a joint model 
Hatzivassiloglou and McKeown (1997) have also developed an algorithm for predicting semantic orientation 
Furthermore since there are a lot of good parsers for English data Meena and Prabhakr (2007) and Liu and Seneff (2009) utilized sentiment structure information by such parsers such as Berkeley Parser 
Kim and Hovy (2004) among others have combined the two tasks identifying subjective text and detecting its sentiment polarity 
Previous research has shown that in general the performance of the former tend to be superior to that of the latter (Mullen and Collier 2004 Lin and He 2009) 
For instance Pang and Lee (2004) refine the accuracy of sentiment analysis by considering only the subjective sentences of a review as determined by an independent classifier 
Specifically aspect rating as an interesting topic has also been widely studied (Titov and McDonald 2008a Snyder and Barzilay 2007 Goldberg and Zhu 2006) 
Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al 2005 Kennedy and Inkpen 2006 Kanayama and Nasukawa 2006 Devitt and Ahmad 2007 Sadamitsu et al 2008) 
As an example they present the following three sentences (Hatzivassiloglou & McKeown 1997) 1 
As per (Pang and Lee 2005) REG indicates SVM-R which is the baseline ordinal regression method 
Inter-sentential contexts as in our approach were used as a clue also for subjectivity analysis (Riloff and Wiebe 2003 Pang and Lee 2004) which is two-fold classification into subjective and objective sentences 
Text excerpts are usually extracted through string matching (Hu and Liu 2004a Popescu and Etzioni 2005) sentence clustering (Gamon et al 2005) or through topic models (Mei et al 2007 Titov and McDonald 2008) 
Popescu and Etzioni (2005) present a method that identifies product features for using corpus statistics WordNet relations and morphological cues 
More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (eg (Wilson et al 2005 Ikeda et al 2008 Sadamitsu et al 2008)) 
Lexicon constructed by combining the lexicon built in Riloff and Wiebe (2003) with other sources1 
Hatzivassiloglou and McKeown (1997) described an unsupervised learning method for obtaining positively and negatively oriented adjectives with accuracy over 90% and demonstrated that this semantic orientation or polarity is a consistent lexical property with high inter-rater agreement 
Previous work on sentiment analysis has covered awide range of tasks including polarity classification (Pang et al  2002 Turney 2002) opinion extraction (Pang and Lee 2004) and opinion source assignment (Choi et al  2005 Choi et al  2006) 
The rules presented by Choi and Cardie (2008) are however much more specific as they define syntactic contexts of the polar expressions 
SVM with unigrams & binary weights (Pang et al 2002) reported at (Pang and Lee 2004) 8715% Hybrid SVM with Turney/Osgood Lemmas (Mullen and Collier 2004) 86% SVM with min-cuts (Pang and Lee 2004) 872% SVM with appraisal groups 902% (Whitelaw et al 2005) SVM with log likehood ratio feature selection (Aue and Gamon 2005) 9045% SVM with annotator rationales 922% (Zaidan et al 2007) LDA with filtered lexicon subjectivity detection (Lin and He 2009) 846% The approach is straightforward intuitive computationally efficient doesnt require additional human effort and takes into consideration standardized and tested notions from IR 
Our focus is on the sentence level unlike (Pang et al  2002) and (Turney 2002) we employ a significantly larger set of seed words and we explore as indicators of orientation words from syntactic classes other than adjectives (nouns verbs and adverbs) 
Several applications in information extraction and sentiment analysis are close in spirit to our work (Pang and Lee 2004 Patwardhan and Riloff 2007 McDonald et al 2007) 
PMI++ is an extended version of (Turney 2002)s method for finding the SO label of a phrase (as an attempt to deal with context-sensitive words) 
For example (Spertus 1997) developed a system to identify inflammatory texts and (Turney 2002 Pang et al  2002) developed methods for classifying reviews as positive or negative 
W(ST) = summation display uSvT w(uv) Globally optimal minimum cuts can be found in polynomial time and near-linear running time in practice using the maximum flow algorithm (Pang and Lee 2004 Cormen et al 2002) 
Many of the subjective clues are from manually developed resources including entries from (Levin 1993 Ballmer and Brennenstuhl 1981) Framenet lemmas with frame element experiencer (Baker et al  1998) adjectives manually annotated for polarity (Hatzivassiloglou and McKeown 1997) and subjectivity clues listed in (Wiebe 1990) 
There has been a lot of research in determining the sentiment of words and constructing polarity dictionaries (Hatzivassiloglou and McKeown 1997 Wiebe 2000 Rao and Ravichandran 2009 Mohammad et al 2009 Velikovich et al 2010) 
Also even the two-category version of the rating-inference problem for movie reviews has proven quite challenging for many automated classi cation techniques (Pang Lee and Vaithyanathan 2002 Turney 2002) 
Current baseline methods often use bag-of-words representations which cannot properly capture more complex linguistic phenomena in sentiment analysis (Pang et al 2002) 
Often lexicons are combined with machine learning for improved results (Wilson et al 2005) 
Here the verbs prevent and ease act as content-word negators (Choi and Cardie 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive 
Other related work includes subjective/objective analysis (Hatzivassiloglon and Wiebe 2000 Riloff and Wiebe 2003) and opinion mining and summarization (Liu et al 2005 Popescu and Etzioni 
We will employ the structural correspondence learning (SCL) domain adaption algorithm used in (Blitzer et al 2007) for linking the translated text and the natural text 
Training Set (Labeled English Reviews) There are many labeled English corpora available on the Web and we used the corpus constructed for multi-domain sentiment classification (Blitzer et al 2007) 9  because the corpus was large-scale and it was within similar domains as the test set 
Earlier research had been studied unsupervised (Kim et al 2004) supervised (Pang et al 2002 Pang et al 2005) and semi-supervised approaches (Goldberg et al2006)fort he classification 
Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentiment-bearing words 
In (Wilson et al 2005) this decision is left to the classifier 
Sentiment summarization has been well studied in the past decade (Turney 2002 Pang et al 2002 Dave et al 2003 Hu and Liu 2004a 2004b Carenini et al 2006 Liu et al 2007) 
Most previous work is centered around a given sentiment lexicon or building one via heuristics (Kim and Hovy 2007 Esuli and Sebastiani 2007) manual annotation (Das and Chen 2001) or machine learning techniques (Turney 2002) 
While we do not have a direct comparison we note that Turney (2002) performs worse on movie reviews than on his other datasets the same type of data as the polarity dataset 
Most of the work in sentiment analysis has focused on supervised learning techniques (Sebastiani 2002) although there are some notable exceptions (Turney 2002 Lin and He 2009) 
Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models both heuristic and machine learned to improve phrasal sentiment analysis 
Firstly the negation modeling in (Wilson et al 2005) is considerably more complex and secondly Wilson et al 
The local dependencies between sentiment labels on sentences is similar to the work of Pang and Lee (2004) where soft local consistency constraints were created between every sentence in adocument and inference wassolved using a min-cut algorithm 
Riloff and Wiebe (2003) state that It is [very hard] to obtain collections of individual sentences that can be easily identified as subjective or objective the polarity-dataset sentences for example have not 4Available at wwwcscornelledu/people/pabo/movie review-data/ (review corpus version 20) 
Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity we invent our own version as shown in Figure 2 
Early research on document-level sentiment classification employed conventional machine learning techniques for text categorization (Pang et al 2002) 
We elect to use boolean attributes since they have been shown to be advantageous over term-frequency approaches for sentiment detection particularly when SVMs are employed (Pang et al 2002) 
Negation_Dic en  88 negation terms were collected from the feature file valence shifterstff used in the work (Wilson et al 2005a Wilson et al 2005b) 
It is well-known that sentiment classification is very domain-specific (Blitzer et al 2007) so it is critical to eliminate its dependence on a large-scale labeled data for its wide applications 
Cascaded models for fine-to-coarse sentiment analysis were studied by Pang and Lee (2004) 
Specifically we construct features using polarity lexicons (used by (Wilson et al 2005)) DA tags (used by (Somasundaran 3Local is supervised as previous work has shown that supervised methods are effective in opinion analysis 
The second step is to estimate the semantic orientation of each extracted phrase (Hatzivassiloglou & McKeown 1997) 
Considering the amount of improvement that is achieved by negation modeling the improvement seems to be larger in (Wilson et al 2005) 
In both cases there 1 Alternatively decisions from the sentence classifier can guide which input is seen by the document level classifier (Pang and Lee 2004) 
Mullen and Collier (2004) used SVMs and expanded the feature set for representing documents with favorability measures from a variety of diverse sources 
However modeling proximity relationships between sentences would enable us to leverage coherence text spans occurring near each other (within discourse boundaries) may share the same subjectivity status other things being equal (Wiebe 1994) 
We generate initializations using Opinion Finder (Wilson et al 2005) which were shown to be a reasonable substitute for human annotations in the Movie Reviews dataset (Yessenalina et al 2010)6 We consider two additional (baseline) methods for initialization using a random set of sentences and using the last 30% of sentence in the document 
Task of predicting document-level star ratings was considered in (Pang and Lee 2005 Goldberg and Zhu 2006) 
Subsequently many other studies make efforts to improve the performance of machine learning-based classifiers by various means such as using subjectivity summarization (Pang and Lee 2004) seeking new superior textual features (Riloff et al 2006) and employing document subcomponent information (McDonald et al 2007) 
Finally solutions that attempt to handle the error propagation problem have done so by explicitly optimizing for the best combination of document and sentence-level classification accuracy (McDonald et al 2007) 
Note that our result on Dataset A is as strong as that obtained by Pang and Lee (2004) via their subjectivity summarization algorithm which retains only the subjective portions of a document 
The token precision is higher than 90% in all of the corpora including the movie domain which is considered to be difficult for SA (Turney 2002) 
Sample similarity in the multi-way sentiment detection setting has previously been considered by using Support Vector Machines (SVMs) in conjunction with a metric labeling meta algorithm (Pang and Lee 2005) by taking a semi supervised graph-based learning approach (Goldberg and Zhu 2006) and by using optimal stacks of SVMs (Koppel and Schler 2006) 
Second movie reviews are apparently harder to classify than reviews of other products (Turney 2002 Dave Lawrence and Pennock 2003) 
Others were derived from corpora including subjective nouns learned from unannotated data using bootstrapping (Riloff et al  2003) 
Much work has been performed on learning to identify and classify polarity terms (ie  terms expressing a positive sentiment (eg  happy) or a negative sentiment (eg  terrible)) and exploiting them to do polarity classification (eg  Hatzivassiloglou and McKeown (1997) Turney (2002) Kim and Hovy (2004) Whitelaw et al 
Consequently these methods generally do not perform well while methods which incorporate sample similarity information achieve improved performance (Pang and Lee 2005) 
In recent years sentiment classification has drawn much attention in the NLP field and it has many useful applications such as opinion mining and summarization (Liu et al 2005 Ku et al 2006 Titov and McDonald 2008) 
For instance in Pang and Lee (2004) yd would be the polarity of the document and ysi would indicate whether sentence si is subjective or objective 
Other approaches for sentence-level sentiment detection include (Yu and Hatzivassiloglou 2003 Grefenstette et al 2004 Ikeda et al 2008) 
(Turney 2002) used patterns representing part-of-speech sequences (Hatzivassiloglou and McKeown 1997) recognized adjectival phrases and (Wiebe et al  2001) learned N-grams 
This is reported in studies of manual annotation of phrases (Takamura et al  2006) recognizing contextual polarity of expressions (Wilson et al  2005) and sentiment tagging of words and word senses (Andreevskaia and Bergler 2006 Esuli and Sebastiani 2006) 
As seed words we used subsets of the 1336 adjectives that were manually classified as positive (657) or negative (679) by Hatzivassiloglou and McKeown (1997) 
Several works (Wiebe 2000 Turney 2002 Riloff 2003 Whitelaw et al 2005) use lexical resources and decide whether a sentence expresses a sentiment by the presence of lexical items (sentiment words) 
Still another is identifying the type of a subjective expression (eg  positive or negative evaluative) extending work such as Hatzivassiloglou and McKeown (1997) on classifying lexemes to the classification of instances in context (compare eg great! and oh great) In addition it would be illuminating to apply our system to data annotated with discourse trees (Carlson Marcu and Okurowski 2001) 
Others combine additional feature types for this decision (Yu and Hatzivassiloglou 2003 Kim and Hovy 2004 Wilson et al 2005 Bloom et al 2007 McDonald et al 2007 Titov and McDonald 2008a Melville et al 2009) 
Popescu and Etzioni (2005) achieved high-precision opinion phrases extraction by using relaxation labeling 
Others use sentence cohesion (Pang and Lee 2004) agreement/disagreement between speakers (Thomas et al 2006 Bansal et al 2008) or structural adjacency 
Liu and Seneff (2009) claim however that this is an oversimplification of language 
We use the subjectivity lexicon of (Wilson et al 2005)2 which contains approximately 8000 words which may be used to express opinions 
It is of particular interest that using tfi in the document representation usually results in decreased accuracy a result that appears to be in contrast with topic classification (Mccallum and Nigam 1998 Pang et al 2002) 
Second some solutions for incorporating sentence level information lack mechanisms for controlling how errors propagate from the subjective sentence identification subtask to the main document classification task (Pang and Lee 2004) 
Their best attained performance using a filtered subjectivity lexicon and removing objective sentences in a manner similar to Pang and Lee (2004) is only slightly lower than that of a fully-supervised approach 
In earlier work (Turney 2002) only singletons were used as seed words varying their number allows us to test whether multiple seed words have a positive effect in detection performance 
