One
semiautomatic
approach
evaluation
ROUGE
(Lin
Hovy
2003)
primarily
based
ngram
co-occurrence
automatic
human
summaries
Automatic
text
summarization
approaches
offered
reasonably
well-performing
approximations
identifiying
sentences
2002
Schiffman
al
Erkan
Radev
2004
Mihalcea
Tarau
Daume
Marcu
2006)
surprisingly
(re)generation
major
challange
despite
sub-sentential
modification
(Jing
McKeown
2000
Knight
Barzilay
2005)
We
selected
TextRank
performance
competitive
top
systems
participating
DUC
02
(Mihalcea
2004)
These
methods
usually
represent
documents
term-sentence
matrices
(where
row
represents
sentence
column
term)
graphs
node
edge
pairwise
relationship
corresponding
sentences)
ranks
according
scores
calculated
set
predefined
features
term
frequency
inverse
(TF-ISF)
(Radev
Lin
2002)
position
(Yih
2007)
keywords
The
experiments
reported
inspired
previous
content
selection
(Kupiec
1995)
rhetorical
classification
(Teufel
Moens
information
(Lapata
Graph-based
(Erkan
Wan
2007b)
proposed
rank
passages
PageRank
algorithm
variants
Table
Sentence
scoring
metrics
Name
Description
Source
POS
F
Closeness
beginning
document
1i
(Edmundson
1969)
L
(Baxendale
1958)
B
borders
max(1i
1ni+1)
1997)
LEN
W
Number
words
(Satoshi
2001)
CH
characters
sentence5
LUHN
maxi{clusters(S)}{CSi}
CSi
W2iNi
(Luhn
KEY
Sum
frequencies
summation
textt{Keywords(S)}
tf(t)
COV
Ratio
(Coverage)
|Keywords(S)||Keywords(D)|
(Liu
2006a)
TF
Average
summationtext
tS
N
(Vanderwende
TFISF
summationtexttS
isf(t)
log(n(t))log(n)
(Neto
2000)
n(t)
containing
SVD
Length
vector
V
T
computing
Singular
Value
(Steinberger
Jezek
Decomposition
matrix
A
UV
TITLE
O
Overlap
similarity6
title
sim(ST)
|ST|min{|S||T|}
J
Jaccard
similarity
|ST||ST|
C
Cosine
sim(vectorS
vectorT)
cos(vectorS
vectorSvectorT|vectorS||vectorT|
D
complement
sim(SD
S)
|ST|min{|S||DS|}
|ST||SDS|
vectorD
vectorS
vectorDS|vectorS||
vectorDS|
DEG
extensions
measures
respectively
graph-based
baselines
single
described
follows
BasicRank
This
baseline
adopts
basic
relationships
similar
summarizers
found
produce
quantitatively
results
significantly
outperform
summarizer
MEAD
framework
options
default
corpus
Teufel
(2002)
Skip-bigram
pair
allowing
arbitrary
gaps
n-gram
cooccurrence
machine
ideal
To
evaluate
system
pyramid
method
(Nenkova
Passonneau
level
In
called
signature
terms
descriptive
input
identified
using
log-likelihood
ratio
word
Gupta
evaluating
Existing
abstractive
limited
categorized
categories
(1)
prior
knowledge
1998)
(Finley
Harabagiu
(DeJong
1982)
(2)
Natural
Language
Generation
(NLG)
(Saggion
Lapalme
Repetition
exploited
indicator
importance
1958
1999
Nenkova
Alternatively
reward
occupy
positions
discourse
structure
(Ono
Sumita
Miike
1994
1997b)
For
example
coherence
NLG
potentially
inform
Vectors
contain
topic
signatures
summary
Topic
highly
determined
application
loglikelihood
test
particular
ROUGE-2
recall
bigrams
human-written
LexPageRank
algorithms
HITS
compute
Such
(2000)
introduce
weighting
scheme
Luckily
variety
theories
developed
(eg
Mann
Thompson
1988
Grosz
Weinstein
Joshi
1995
Halliday
Hasan
1976)
(Barzilay
Elhadad
1997
generation
applications
(Scott
de
Souza
1990
Kibble
Power
Following
current
practice
particularly
DUC3
package
More
extensive
experimental
(1997)
describe
technique
building
lexical
chains
extractive
human-generated
250-word
surveys
Typical
existing
include
centroid-based
2004))
graph-ranking
non-negative
factorization
(NMF)
(Lee
Seung
2001))
Conditional
random
field
(CRF)
(Shen
LSA
(Gong
Liu
third
compare
machine-made
model
abstractsThe
suggest
suited
indicative
short
stories
evaluation1
mainly
concern
ROUGE1
As
mentioned
Section
focused
cohesion
(Sjorochodko
1972
global
(Marcu
Pyramid
value
factoids
Recently
ranking
LexRank
instance
Boguraev
Kennedy
anaphoric
relations
whereas
operationalize
via
sequences
related
spanning
topical
unit
(Morris
Hirst
1991)
Relative
Utility
Early
studies
cosine
(with
schema)
peer
(Donaway
various
vocabulary
overlap
n-grams
common
subsequence
(Page
(Kleinberg
1999)
recently
applied
successfully
multi-document
idea
introduced
task
investigated
including
cue
stigma
1969
Most
research
domain
independent
tasks
extraction
Salton
unsupervised
Jing
supervised
(Ouyang
2007
Shen
Li
2009)
System
overview
31
Signature
Terms
Extraction
There
texts
rely
trainable
phrase
(Banko
strategies
pick
appropriate
abstracted
recent
techniques
sort
fragments
(Papineni
translation
Nowadays
widespread
offers
statistics
models
Lapata
(2003)
Cartesian
product
adjacent
Empirical
evaluations
standard
metricsthe
2004b)
2004)show
performing
CRF
incorporating
order-2
Markov
dependencies
skip-chain
achieves
913%
score
outperforms
best-performing
non-sequential
39%
With
011
00925
2006
5This
threshold
derived
experimentally
data
produced
Simfinder
salience
computed
1991
below
According
sub-metrics
ROUGE-N
(N=1
2)
relatively
simple
partition
aims
develop
manual
criteria
determining
quality
typified
single-document
Halteren
strategy
(2004)
performed
widely
recognized
automated
distinguish
types
links
stated
identify
citation(s)
linguistic
expression
attributable
1We
list
40
methodology
nouns
eg
study
account
investigation
result
etc
demonstrate
scientific
attribution
studied
utility
annotation
Argumentative
Zoning
intermediate
step
process
Comparing
Machine-Made
Summaries
Manually
Created
Extracts
Measuring
co-selection
created
humans
tradition
community
family
well-known
shortcomingsAs
remarked
occasions
(Mani
2001
al2003)
provide
complete
assessment
summaryFirst
question
contains
appear
extracts
uninformative
inappropriate
inclusion
summaryIn
addition
internal
inter-dependentTherefore
reference
mean
advisable
respect
builds
conditional
focusing
semantic
roles
Evaluation
evaluated
BLEU
built-in
preference
shorter
translations
system-produced
voting
recommendations
2005
Yang
straightforward
approximating
fusion
multi
(Carbonell
Goldstein
1998
Budzikowska
Gerber
(nouns
verbs
adjectives)
stopword
Yoshioka
relevance
(similarity)
dif1The
routinely
tool
adopted
exactly
demonstrated
correlated
coverage
2003a
Like
Mani
Barzil~'s
focuses
identi~"
differences
similarities
form
actual
summar
(Sparck
1993)
(McKeown
NIST
automatically
Among
unigram-based
(ROUGE-1)
shown
agree
judgment
Responsiveness
differs
SEE
concept
eigenvector
centrality
Official
utilizes
jackknife
procedure
assesses
significance
bootstrapping
resampling
rankings
correlate
adapted
experiment
considered
unigrams
(lemmatized
excluding
stop
words)
ErKan
keyword
Machine
learning
individual
affects
Witbrock
Mittal
(1999)
statistical
choose
phrases
syntactic
context
Predicates
tendency
appearing
towards
abstract
predicted
position-based
machine-generated
metric
measure
agreement
annotators
create
extract
length
simply
add
Summary
datasets
toolkit
(ie
ROUGEeval-142
study)
sentence-level
inter-sentence
indicate
improves
increasing
observed
Tam
2003
2003b
Kolluru
Gotoh
little
attention
paid
development
specific
user
available
suitable
(based
bigrams)
ROUGE-SU4
skip-bigrams
separated
official
St-Onge
(1998)
greedily
disambiguate
soon
encountered
selecting
sense
strongly
chain
consider
alternatives
senses
paper
relying
iterative
previously
languages
requirements
additional
Later
merged
regeneration
extracted
improve
employed
proven
judgments
Bleu
tested
(Pastra
Saggion
probability
It
bases
N-gram
compares
generated
judges
(MDS)
Perhaps
relevant
defined
argumentative
zoning
especially
ones
computational
linguistics
propose
orderings
basis
distance
By
analyzing
aim
background
solution
citation
obtain
abstracts
influential
contents
articles
Mei
Zhai
2008)
learned
suitability
ROUGE-1
First
estimates
generic
query-focused
Vanderwende
Conroy
Lacatusu
Unlike
directly
utilize
noun
(NP)
coreference
2008
employs
insertion
substitution
modify
chunk
lead
implementation
centroid
cluster
centroids
TFIDF
NeATS
adds
clustering
select
MMR
(Goldstein
remove
redundancy
decided
deeper
(van
relative
2003)The
reason
practical
unfortunate
disadvantage
considerably
labor-intensive
Conceptual
units
observable
snippets
properties
satisfy
status
paragraph
source
Simply
variant
Bilingual
Understudy
(BLEU)
linear
combination
matching
output
summary)
promising
sufficient
2002b)
Co-selection
precision
co-selected
Kappa
(Siegel
Castellan
Carletta
1996)
Related
addressed
revising
nugget-based
Demner-Fushman
Hildebrandt
Voorhees
Very
briefly
spirit
concurrently
graph
representation
represented
nodes
weighted
edges
drawn
inter-sentential
Our
Kappa=048
Macro-F=053
published
(Kappa=045
Macro-F=050
(2002))
usual
domain-specific
determine
priori
originating
included
earthquakes
victims)
White
exist
salient
oll
distribution
(Zechner
(Salton
(Teufell
symbolic
(Barzil~v
Some
extended
deal
Bloedern
Carbonell
TIPSTER
1998b
Bloedorn
!999
Stein
Lexical
capture
promise
producing
survey
creation
examine
distinctions
comparing
sophisticated
post
revision
grammar-based
investigating
issues
positional
indicators
1964)
occurrence
(Mathis
1973)
probabilistic
token
implicit
Pyramids
systematically
scale
look
solutions
seeking
robust
templates
filled
extracting
specialized
sources
doc"ument
generating
natural
language
com-
paring
named-entities
lists
section
(TIPSTER
1998b)
finding
co-reference
sections
activation
networks
items
(identity
mappings
synonyms
hypernyms
etc)
manually
provided
in-depth
discussion
issue
papers
2003b)
understanding
induced
(Paice
Johns
events
(Filatova
Hatzivassiloglou
While
earlier
compression
reduction
rules
(Grefenstette
Gates
aligned
written
constituents
reduced
(Knight
Reizler
[Mani
1999]
referencing
pronouns
Corpus-based
notion
schemata
explored
past
Lee
summarisation
DP
167
323
PBMT
186
516
Summ
839
1425
QA
238
202
TE
56
44
Clusters
network
size
11
Work
Although
collaboration
Newman
article
author
lot
Position
MEAD*
Other
exploit
concepts
constraints
Technical
1981
Paice
Jones
1993
explore
emphasize
impact
Moreover
Basic
Element
(Hovy
(Passonneau
counting
Volume
36
report
people
constitute
(Rath
Resnick
Savage
1961
al1997
2003)In
042
sufcient
creating
resource
interpret
acceptable
facet
commonly
reporting
publications
definition
candidate
eliminates
excerpts
Therefore
difficult
Graphs
undirected
Many
broadly
characterized
TERM-BASED
attempt
main
topics
TERMS
Furthermore
themselves
follow
employing
Kendalls
a7
OSO
underlying
assumption
reasonable
fairly
reliable
diagnostic
Abstraction
hand
relies
processing
followed
structural
compaction
interpretation
condensed
retain
asserted
Quality
measuring
connectivity
successful
degree
Wolf
Gibson
Cohesion
rhetorical-based
parsing
decide
elaboration
evaluates
maxium
overlapping
property
unique
effect
time
perspective
Previous
feasible
[Jing
2000]
suggested
informative
correct
errors
Then
apply
coherent
template
slots
analysis
worst
a4a6a5
a40
a39
An
difficulty
setting
Lapatas
state-of-the-art
doesnt
permutations
(see
below)
0053
scorer
considers
calculating
local
General
(Kraaij
Kraaij
formulation
computes
NP-rewrite
enhanced
Frequency
frequency-related
traditionally
true
relates
surrounding
Pedersen
Chen
They
marginal
increase
decline
Thus
Rouge-1
unigrams)
correlation
(Conroy
SummBank
Because
accepted
postprocessing
final
shortening
fusing
otherwise
material
deviates
insofar
learn
preferences
pairs
formalized
construct
non-trivial
adapt
require
curated
outputs
Questions
regarding
raised
currently
partially
answered
(Halteren
criterion
chronological
augmented
email
(Wan
(Nomoto
Matsumoto
OLeary
Amini
Gallinari
advanced
query
expansion
grammatically
expected
answer
sets
marked
Two
focus
stage
Silber
McCoy
examines
tools
constructing
resources
infobox
Finally
implement
variation
validation
claimed
correlates
ratings
Dang
(2006)
compared
bigram
(the
baseline)
improved
version
trained
Human
correlations
informativeness
(ErKan
2003a)
recall-based
unigram
predicting
counterpart
improvements
Aim
322
Ctr
Txt
Own
Bkg
Bas
Oth
P
34
57
84
37
52
R
65
20
66
88
50
39
26
61
86
38
Correctly
Classified
Instances
725%
statistic
045
Macro-F
050
(2002)s
AZ
(Naive
Bayes
Classifier)
themes
linguistically
motivated
descendent
Elements
(BE)
(human)
larger
comparison
parsers
notable
discussing
usefulness
limitations
23
Single
Meta
algo
researchers
impressed
Translation
(MT)
allowed
MT
quickly
cheaply
ideas
(Kan
composition
headers
paradigm
coupled
identification
abstraction
paradigms
methodologies
(LCS)
(Hori
2004a
2004b
Och
heuristically
homogeneity
learners
Weka
settings)
NB
Naive
learner
HNB
Hidden
IBk
Memory
J48
Decision
tree
STACKING
combining
classifiers
stacking
History
feature
run
twice
prediction
(as
noticed
slight
improvement
history
(between
005
01
MacroF
learners))
155
evaluation2
proved
strong
makes
assess
selects
utterances
match
obtained
leave-one-out
comparisons
references
(Table
7)
(3)
optimal
explained
Alternatives
473
Computational
Linguistics
24
key
(Halliday
training
construction
paragraphs
(Mitra
Singhal
Buckley
counts
matches
Next
remaining
ranked
sum
a)
authority
b)
Gene
Ontology
(GO)
gene
annotated
(To
date
190000
genes
associated
GO
terms)
growing
string-edit
type
intrinsic
details
Inspired
collectively
efforts
disambiguation
sentiment
(Pang
retrieval
answering
(Otterbacher
Note
includes
optional
takes
days
ours
tractable
Naturally
component
cohesive
readable
extrinsic
(Sparck-Jones
regardless
maximizing
SCU
weights
maximum
SCUs
genre-specic
ctionTo
performers
Document
Understanding
Conference
(henceforth
DUC)
annual
competition
summarizersIn
competitions
assigned
(ranking
readability
grammaticality
non-redundancy
referential
clarity
coherence)
2004)There
unied
straightforwardWe
chose
GISTexter
(Harabagiu
Hickl
CLASSY
(Schlesinger
Schlesinger
2007)GISTexter
appears
judgesApart
consistently
second-best
characteristics
exception
eighth)CLASSY
scoresThe
received
Features
publication
Althaus
role
911
a0a2a1a3a1
a0a0
a0a2a1a4a0a2a1a5
a0
a0a2a1a6
a5a7a5a0
a5a8a1
a5a9a4
a5a7a6
a5a9a10
a0a11a4a11a1
a0a11a4a12a5
a0a11a4a7a4
a13
a6
Figure
Graph
(2003)s
(2004)s
tailored
experience
bias
regard
subsequently
http//irohsuedu/genomics/
discard
none
Concepts
overlap)
stateof-the-art
Second
caution
supplement
replacement
comments
Callison-Burch
Osborne
Koehn
wide
margin
gap
78
percentage
extension
Lins
contrast
explicitly
2The
collections
http//wwwcsail
Systems
evalatued
repeat
differing
entities
examples
frait
1983
Kupiec
Klavans
Shaw
MeKeown
Aon
Mitra
Baldwin
Mortbn
Strzalkowski
multiple
docmnents
Statistical
fragment
classes
cue-based
keywordor
frequency-based
Edmundson
Neto
Steinberger
Kallel
title-based
Satoshi
length-based
concentrate
annotations
nuggets
covered
equivalent
(SCU)
usable
general-domain
RST
[Marcu
1997]
Recall
fitness
function
maximized
optimization
Rank
sentence-tosentence
popular
(Chandrasekar
Doran
Bangalore
1996
Grefenstette
parallel
instances
2000))
levels
textual
scored
c1
c2
c3
c4
c5
t1
t2
t3
t4
Matrix
Summarization
Model
covers
added
pre-defined
structures
hierarchy
structured
Daume-III
Eisenstein
Tang
2009
Wang
terrorism)
achieved
operators
integrate
referring
event
allows
expressed
contrasts
summarization(Mani
EBloedorn
TAC
track
human-based
system-generated
occur
novel
(ieROUGEeval-142
Conferences2
(DUC)
assume
derivable
leverage
re-score
conceptual
(Hatzivassiloglou
2004)a
summariesThis
64
serves
domain-independent
\[McKeown
1999\]
generates
reformulation
\[Barzilay
avoid
misleading
reader
juxtaposed
dates
yesterday
explicit
stamps
2002a)
Once
coreD
adding
equal
Rouge
(models
ROUGE-L
sequence)
perform
Another
equally
But
Donaway
Drummey
Mather
404
28
receive
(but
presumably
equivalent)
exploration
generate
density
(pdf)
distributions
domains
judge
overall
goodness
meant
fluency
considerations
authors
address
shortcomings
argue
predictive
tried
TF*IDF
Ventence
constructed
Semantic
Content
Units
toolkit1
Ngram
WordRank
traditional
(RU)
consist
variable
Introduction
decade
curiously
restricted
scope
applicationsA
innovative
directions
emerged
headline
(Soricut
books
Ceylan
personalized
(Daz
Gervas
tables-of-contents
(Branavan
Deshpande
speech
(Fuentes
al2005)
dialogues
evaluative
(Carenini
Ng
Pauls
biomedical
(Reeve
Han
Brooks
2007)In
venturing
purely
(Krahmer
Marsi
van
Pelt
Nomoto
McDonald
2006)By
revolves
rigid
structureThe
news
medical
(Elhadad
legal
(Moens
computer
science
2008)Although
summarizing
genres
formidable
challenge
excludes
continually
informal
electronicallySuch
ranging
novels
personal
Web
pages
offer
wealth
merits
English
Earlier
conjunction
allow
specifically
designed
language-specific
recall-oriented
term-based
central
Gong
coreference(or
anaphora-)
(Baldwin
Morton
Azzam
Bergler
Stuckardt
running
coreferenceor
resolver
text1
aware
On
accurate
Prager
Samn
Clarke
Cormack
Lynam
Dumais
Chu-Carroll
(Hirao
vectorial
initial
intra
(Wolf
topic-focused
update
sare
ROUGE-SU
corpus-based
dominate
BLEU-type
Automated
representsrecallovervariousn-grams
asystem-generated
summaries5
removed
typical
journalistic
writing
style
newsworthy
comes
candidates
(Brandow
Mitze
Rau
revise
Otterbacher
leveraged
somewhat
disheartening
superior
parser
build
trees
produces
span
Pastra
whom
inspect
Bleu-like
bigram-based
(ROUGE-2)
fits
Text
structuring
Karamanis
information-ordering
Each
provides
content-based
(N
1)
estimate
restriction
optimizing
many-to-many
alignments
preliminary
n-gram-based
(1997a)
evidence
deliver
consistency
implemented
305
adapting
opensource
rst
U
stands
understudy)
contributions
At
extreme
detailed
ve
sting-edit
overly
verbose
biased
subject
shift
target
dierent
events(Radev
contests
officially
employ
http//haydnisiedu/ROUGE/
rewards
(for
topic-oriented
summaries)
theme
(Buckley
Cardie
achieve
appropriately
open-source
suit
purposes
Much
devoted
discourse-level
flow
appear)
(1969)
Since
range
values
separately
induce
total
summing
(theme)
(Number
theme)
(Similarity
(Sum
semantically
wordsare
tightly
connected
useful
verify
subjective
ie
ROUGE-S
variations
following
skip
distances
infinity
special
genre
journal
reliably
2003)1
Throughout
seeks
95%
confidence
ROUGE-S(U)
closely
Non-extractive
gist
(Berger
translation-like
(Witbrock
generative
(De
Jong
1982
Fum
1986
Reihmer
Hahn
1989)
Association
35
(Doddington
Papineni
due
implicitly
accounts
subsumption
summariesGiven
gold-standard
(usually
people)
questionThe
oneDepending
consideration
SU4
metric1
Weakly-constrained
truncated
K
Yih
al(2007)used
tack
decoding
modi
cation
emphasizes
integral
extensively
thesis
fall
own
meetings
2004a)
repetitions
infrequent
express
figure
emanate
sentence)
Present
(Watanabe
clues
calculate
918
occurrences
original
resulting
MTstyle
commonly-used
representations
From
view
imported
proportion
(Summary
SCUs)
ROUGE-SN
denotes
(4
more)
ROUGE-SU2
bi-grams)
Johnson
1992
Zechner
Luhn
(reproduced
category
Opinosis
composed
sentence-by-sentence
presupposing
publicly
2004)to
andF-scorefor
ROUGE5
supposed
correspondence
exponential
efficiency
(Hirst
[Radev
2002]
environment
users
(Tombros
Sanderson
low
project
intrinsically
human-annotated
extrinsically
acquired
labelled
fOwn
Background
Textual
Basis
Contrastg
argument
namely
tagging
coreference/lexical
occurrence/structural
1994)
(Edmunson
(Kuipec
headlines
Ranking
Kleinbergs
Googles
(Brin
Page
Web-link
social
Log-likelihood
(TF
IDF)
Brandow
partial
Tait
bottom-up
top-down
acquisition
(Rau
Jacobs
Zernik
recognition
thematic
(Hahn
1990)
(Benbrahim
Ahmad
theory
collection
consisting
D1Dn
describing
(or
related)
narrative
conventional
2003)4
LEAD
introduction
leading
re
ect
expect
summarize
However
progress
encouraging
evaluators
objective
implementations
empirical
Revision
Based
gold
rest
Amazon
coarser
ignoring
labels
(Binary
labels)
Extractive
involves
assigning
saliency
paragraphs)
Topic-oriented
initiatives
testbeds
alternative
(Over
Equation
applic
ation
Generally
reducing
BE
ROUGE-155
